{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c33106",
   "metadata": {},
   "source": [
    "# Description:\n",
    "This Jupyter notebook contains all python functions developed for the galactic noise study in order\n",
    "to allow for easy importing. The common functions are organised per notebook in which they were first used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15853de",
   "metadata": {},
   "source": [
    "# Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f07ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import scipy.fft as scfft\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import os\n",
    "import scipy.integrate\n",
    "from scipy.optimize import curve_fit\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881f8e7",
   "metadata": {},
   "source": [
    "# Define Constants:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1271bb9",
   "metadata": {},
   "source": [
    "# Galaxy Stacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aef62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from astropy.coordinates import EarthLocation\n",
    "from astropy.time import Time\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72387df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADCtoVoltageTemp(ADCCounts):\n",
    "    ADC_Factor=0.618\n",
    "    ADC_Offset=-8.133 \n",
    "    return (ADC_Factor*ADCCounts + ADC_Offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156e03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LST(TriggerTimes,EvIndex):\n",
    "    \"\"\"Computes the Local Sidereal Time in decimal hours via the astropy module\"\"\"\n",
    "    observing_location = EarthLocation(lat=72.598265*u.deg, lon=-38.459936*u.deg)\n",
    "    observing_time = Time(datetime.utcfromtimestamp(TriggerTimes[EvIndex]), scale='utc', location=observing_location)\n",
    "    T=observing_time.sidereal_time('mean')\n",
    "    return T.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b05c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UTC(TriggerTimes,EvIndex):\n",
    "    \"\"\"Computes the UTC time in decimal hours\"\"\"\n",
    "    T=datetime.utcfromtimestamp(TriggerTimes[EvIndex])\n",
    "    return T.hour+T.minute/60 + T.second/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4599610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyVoltAvg(StNr,ChNr,Runs,NBins=24,ZeroAvg=True,TimeFormat=\"LST\",Triggers=(5,5,5,5),StdCut=-1,FFTFilter=True,Lowpass=False):\n",
    "    \"\"\"\n",
    "    Plots the Average V_RMS as a function of time of the day.\n",
    "    Parameters:\n",
    "    StNr,ChNr,Runs=Station number, channel number, list of runs \n",
    "    NBins=amount of bins to divide the full day in\n",
    "    ZeroAvg=Boolean: if true, the timetraces will firs tbe zero averaged\n",
    "    Lowpass= Boolean: if true, a butterworth lowpass filter will be applied in order to maintain only galactic noise dominated frequencies\n",
    "    FFTFilter=Boolean: if true, applies a Notch filter to all frequency spectra to cut out frequencies which have shown to be potentially problematic\n",
    "    TimeFormat= String: Dictates what timeformat the x-axis will be in. Options: \"LST\": local sidereal time, \"LT\": Local time & \"UTC\": UTC time\n",
    "    Triggers=tupel of flags to dictate which triggers are allowed in the analysis. Events with different triggers are not used (0=has to be absent, 1=has to be present, anything else=both 0 and 1 can be used for analysis)\n",
    "    StdCut=if larger than zero, all VRMS outliers above StdCut standard variations will be cut out of the analysis\n",
    "    \"\"\"\n",
    "    (has_rf,has_ext,has_pps,has_soft)=Triggers\n",
    "    NEvs=0\n",
    "    EventRMS=np.array([]) #Array to store V_RMS value of each event\n",
    "    EventTime=np.array([])#Array to store timestamp of each event\n",
    "    #for (Run, EvNr) in TriggerFilterAlt(StNr, ChNr, Runs,has_rf,has_ext,has_pps,has_soft):\n",
    "    for (Run,EvNr) in TriggerFilterAlt(StNr, ChNr, Runs,has_rf,has_ext,has_pps,has_soft):\n",
    "        path=Path(StNr,Run)\n",
    "        #if os.path.isdir(path+\"/combined.root\"):\n",
    "        if os.path.isfile(path+\"/combined.root\") and os.path.isfile(path+\"/daqstatus.root\"):\n",
    "            NEvs+=1\n",
    "        \n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')        \n",
    "                \n",
    "            EvIndex=np.where(EventNrs==EvNr)[0][0]\n",
    "            VoltageTrace=ADCtoVoltage(RadiantData[EvIndex][ChNr]) #The timetrace data in voltage\n",
    "            if ZeroAvg==True:\n",
    "                Vmean=np.mean(VoltageTrace)\n",
    "                VoltageTrace-=Vmean\n",
    "                #EventRMS=np.append(EventRMS,np.sqrt(np.mean([(V-Vmean)**2 for V in ADCtoVoltage(RadiantData[EvIndex][ChNr])])))\n",
    "            if FFTFilter or Lowpass:\n",
    "                sampling_rate=3.2 * (10**9) #Sampling rate in Hertz according to the python file of NuRadioReco.modules.io.rno_g\n",
    "                TimeStep=1/sampling_rate #Time between two samples\n",
    "                SamplingTimes=np.arange(0,len(RadiantData[0][0])*TimeStep,TimeStep)\n",
    "                freq=scfft.fftfreq(len(SamplingTimes),(SamplingTimes[-1]-SamplingTimes[0])/len(SamplingTimes))\n",
    "                freq=np.fft.fftshift(freq)\n",
    "                TotalFilter=np.ones(len(freq))\n",
    "                if FFTFilter:\n",
    "                    TotalFilter=np.multiply(TotalFilter,NotchFilters([403*10**6,120*10**6,807*10**6,1197*10**6],75,freq,sampling_rate))\n",
    "                if Lowpass:\n",
    "                    CritFreq=110*10**6\n",
    "                    TotalFilter=np.multiply(TotalFilter,LowpassButter(CritFreq,20,freq))\n",
    "                FFT=scfft.fft(VoltageTrace)\n",
    "                FFT=np.fft.fftshift(FFT)\n",
    "                FFT=np.array([FFT[i]*TotalFilter[i] for i in range(len(freq))])\n",
    "                VoltageTrace=np.abs(scfft.ifft(FFT))\n",
    "            \n",
    "            EventRMS=np.append(EventRMS,np.sqrt(np.mean([V**2 for V in VoltageTrace])))\n",
    "                \n",
    "            if TimeFormat==\"LST\":\n",
    "                EventTime=np.append(EventTime,LST(TriggerTimes,EvIndex))\n",
    "            elif TimeFormat==\"LT\": #Greenland Timezone is UTC-3\n",
    "                EventTime=np.append(EventTime,(UTC(TriggerTimes,EvIndex)-3)%24)\n",
    "            else:\n",
    "                print(\"Please enter a valid TimeFormat\")\n",
    "                return\n",
    "                \n",
    "                \n",
    "    #print(np.sum([EventRMS[i] for i in np.arange(len(EventTime)) if EventTime[i]<=.25 ]))\n",
    "    \n",
    "    EventTimeCounts, EventTimeBins=np.histogram(EventTime, bins=NBins,range=(0,24),density=False) #Storing timestamps in histogram format\n",
    "    #Make a histogram of the V_RMS value fully added in its respective bin by adding V_RMS as a weigth to the additions to the histogram\n",
    "    EventRMSCounts, EventRMSBins=np.histogram(EventTime, bins=NBins,range=(0,24),density=False,weights=EventRMS)    \n",
    "    \n",
    "    ##plt.hist(EventTime, bins=NBins,range=(0,24),density=False)\n",
    "    \n",
    "    ##plt.figure()\n",
    "    ##plt.hist(EventTime, bins=NBins,range=(0,24),density=False, weights=EventRMS)\n",
    "    \n",
    "    #RMSBins=np.digitize(EventTime,EventTimeBins) #Array of idx of bin in which the timestamp of each event falls\n",
    "    \n",
    "    ##Make a histogram of the V_RMS value fully added in its respective bin by adding V_RMS as a weigth to the additions to the histogram\n",
    "    #EventRMSCounts, EventRMSBins=np.histogram(RMSBins, bins=24,range=(0,24),density=False,weights=EventRMS)\n",
    "    \n",
    "    \n",
    "    #Compute std per bin\n",
    "    EventTimeDig=np.digitize(EventTime,EventTimeBins)\n",
    "    GroupedVRMS=np.empty((NBins,),dtype=object)\n",
    "    for i in range(len(EventTimeDig)):\n",
    "        GroupedVRMS[EventTimeDig[i]-1]=np.append(GroupedVRMS[EventTimeDig[i]-1],EventRMS[i])\n",
    "    ##Get rid of \"None\" entries in beginning of array\n",
    "    for i in range(len(GroupedVRMS)):\n",
    "        GroupedVRMS[i]=np.delete(GroupedVRMS[i], 0) \n",
    "    \n",
    "    VRMSStd=np.array([np.std(GroupedVRMS[i]) if len(GroupedVRMS[i])!=0 else 0 for i in range(len(GroupedVRMS))])\n",
    "    VRMSMedian=np.array([np.median(GroupedVRMS[i]) for i in range(len(GroupedVRMS))])\n",
    "\n",
    "    \n",
    "    MidBins= np.array([(EventTimeBins[i] + EventTimeBins[i+1])/2 for i in range(0,len(EventTimeBins)-1)])           \n",
    "    VRMSAvg=np.array([EventRMSCounts[i]/EventTimeCounts[i]  if EventTimeCounts[i] !=0 else 0 for i in range(len(EventRMSCounts))])\n",
    "    \n",
    "    if StdCut>=0:\n",
    "        for i in range(len(GroupedVRMS)):\n",
    "            for VRMS in GroupedVRMS[i]:\n",
    "                if VRMS>VRMSMedian[i] + StdCut*VRMSStd[i] or VRMS<VRMSMedian[i] - StdCut*VRMSStd[i]:\n",
    "                    GroupedVRMS[i]=np.delete(GroupedVRMS[i], np.where(GroupedVRMS[i]==VRMS)[0][0])\n",
    "        VRMSAvg=np.array([np.mean(GroupedVRMS[i]) for i in range(len(GroupedVRMS))])\n",
    "        VRMSStd=np.array([np.std(GroupedVRMS[i]) if len(GroupedVRMS[i])!=0 else 0 for i in range(len(GroupedVRMS))])\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.figtext(0.2, 0.8, \"Entries:\" + str(np.sum(EventTimeCounts)), fontsize=18,bbox=dict(edgecolor='black', facecolor='none', alpha=0.2, pad=10.0))\n",
    "    #plt.hist(RMSBins, bins=24,range=(0,24),density=False, weights=[EventRMS[i]/EventRMSCounts[i] for i in range(len(EventRMS))])\n",
    "    plt.errorbar(MidBins,1000*VRMSAvg,yerr=1000*VRMSStd,fmt=\".\",zorder=2)\n",
    "    #for i in range(len(GroupedVRMS)):\n",
    "    #    plt.plot(MidBins[i]*np.ones(len(GroupedVRMS[i])),1000*GroupedVRMS[i],\"r.\", alpha=0.5,zorder=1)\n",
    "    \n",
    "    #plt.plot(MidBins,1000*VRMSAvg,'r.')\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=1,alpha=0.5)\n",
    "    plt.title(\"V_RMS of Station \" + str(StNr) + \", channel \" + str(ChNr) + \" for \" + str(NEvs) + \" events between run \" + str(Runs[0]) + \" and run \" + str(Runs[-1]) + \" throughout the day for \" + str(NBins) + \" bins\")\n",
    "    #plt.ylim(-50,50)\n",
    "    #plt.xlim(0,np.max(SamplingTimes*(10**9)))\n",
    "    plt.xlabel(TimeFormat + \" Time (hrs)\",fontsize=20)#20)\n",
    "    plt.ylabel(\"V_RMS (mV)\",fontsize=20)#20)\n",
    "    plt.xticks(np.arange(0, 24, 1.0),fontsize=25)#15)\n",
    "    plt.yticks(fontsize=25)#15)\n",
    "    #plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84efc135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VRMSTimeOfDay(StNr,ChNr,Runs,t0,t1,TimeFormat=\"LST\"):\n",
    "    EventRMS=np.array([]) #Array to store V_RMS value of each event\n",
    "    EventTime=np.array([])#Array to store timestamp of each event\n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        #if os.path.isdir(path+\"/combined.root\"):\n",
    "        if os.path.isfile(path+\"/combined.root\"):\n",
    "\n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')        \n",
    "            for EvNr in EventNrs:\n",
    "                EvIndex=np.where(EventNrs==EvNr)[0][0]\n",
    "                if TimeFormat==\"LST\":\n",
    "                    t=LST(TriggerTimes,EvIndex)\n",
    "                elif TimeFormat==\"LT\":\n",
    "                    t=(UTC(TriggerTimes,EvIndex)-3)%24\n",
    "                else:\n",
    "                    print(\"TimeFormat \" + str(TimeFormat) + \" is not supported.\")\n",
    "                \n",
    "                if t0<=t<=t1:\n",
    "                    Vmean=np.mean(ADCtoVoltage(RadiantData[EvIndex][ChNr]))\n",
    "                    EventRMS=np.append(EventRMS,np.sqrt(np.mean([(V-Vmean)**2 for V in ADCtoVoltage(RadiantData[EvIndex][ChNr])])))\n",
    "\n",
    "    #plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(len(EventRMS)),1000*EventRMS,\".\")\n",
    "    plt.title(r\"$V_{RMS}$ for the events of Channel\" + str(ChNr) + \" for runs between \" + str(t0) + \" & \" + str(t1) + \" hr \" + TimeFormat)\n",
    "    plt.xlabel(\"Sample Nr\")\n",
    "    plt.ylabel(r\"$V_{RMS}$ (mV)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661f426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvntsPerRun(StNr,ChNr,Runs):\n",
    "    NRuns=0\n",
    "    AmountEvents=np.array([])\n",
    "    ValidRuns=np.array([])\n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        #if os.path.isdir(path+\"/combined.root\"):\n",
    "        if os.path.isfile(path+\"/combined.root\") and os.path.isfile(path+\"/daqstatus.root\"):\n",
    "            NRuns+=1\n",
    "            \n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            #TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')        \n",
    "            AmountEvents=np.append(AmountEvents,len(EventNrs))  \n",
    "            ValidRuns=np.append(ValidRuns,Run)  \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(ValidRuns,AmountEvents,\".\")\n",
    "    plt.figtext(0.2, 0.8, \"Entries:\" + str(np.sum(AmountEvents)), fontsize=18,bbox=dict(edgecolor='black', facecolor='none', alpha=0.2, pad=10.0))\n",
    "    plt.xlabel(\"Run Nr\")\n",
    "    plt.ylabel(\"Amount of events\")\n",
    "    plt.title(\"Amount of events per run for Station \" + str(StNr) + \", channel \" + str(ChNr))\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrigInfo(StNr,ChNr,RunNr):\n",
    "    \"\"\"Reads in the TriggerInfo databranch\"\"\"\n",
    "    CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,RunNr)\n",
    "    TriggerInfo=CombinedFile['combined']['header']['trigger_info'].array(library='np')\n",
    "    return TriggerInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca58641",
   "metadata": {},
   "source": [
    "# Investigating Transit Curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de34fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransitCurves(StNr,ExtraChNr,Runs,NBins=24,ZeroAvg=True,TimeFormat=\"LST\"):\n",
    "    \"\"\"Plots the Vrms values as a function of LST for the upwards facing LPDA's and a chosen channel.\"\"\"\n",
    "    ChNrs=[13,16,19,ExtraChNr]\n",
    "    NRuns=0\n",
    "    EventRMS= np.empty((4,0),float) #Array to store V_RMS value of each event for all four channels\n",
    "    EventTime=np.array([])#Array to store timestamp of each event\n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        #if os.path.isdir(path+\"/combined.root\"):\n",
    "        if os.path.isfile(path+\"/combined.root\") and os.path.isfile(path+\"/daqstatus.root\"):\n",
    "            NRuns+=1\n",
    "        \n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')        \n",
    "                \n",
    "            for EvNr in EventNrs:\n",
    "                EvIndex=np.where(EventNrs==EvNr)[0][0]\n",
    "                #EventRMS=np.append(EventRMS,np.sqrt(np.mean([V**2 for V in ADCtoVoltage(RadiantData[EvIndex][ChNr])])))\n",
    "                if ZeroAvg==True:\n",
    "                    VmeanList=[np.mean(ADCtoVoltage(RadiantData[EvIndex][ChNr])) for ChNr in ChNrs]\n",
    "                    VRMSList=[[np.sqrt(np.mean([(V-VmeanList[i])**2 for V in ADCtoVoltage(RadiantData[EvIndex][ChNrs[i]])]))] for i in range(len(ChNrs))]\n",
    "                else:\n",
    "                    VRMSList=[[np.sqrt(np.mean([V**2 for V in ADCtoVoltage(RadiantData[EvIndex][ChNr])]))] for ChNr in ChNrs ]\n",
    "                EventRMS=np.concatenate((EventRMS,np.array(VRMSList)),axis=1)\n",
    "                \n",
    "                if TimeFormat==\"LST\":\n",
    "                    EventTime=np.append(EventTime,LST(TriggerTimes,EvIndex))\n",
    "                elif TimeFormat==\"LT\": #Greenland Timezone is UTC-3\n",
    "                    EventTime=np.append(EventTime,(UTC(TriggerTimes,EvIndex)-3)%24)\n",
    "                else:\n",
    "                    print(\"Please enter a valid TimeFormat\")\n",
    "                    return\n",
    "                \n",
    "                \n",
    "    #print(np.sum([EventRMS[i] for i in np.arange(len(EventTime)) if EventTime[i]<=.25 ]))\n",
    "    \n",
    "    EventTimeCounts, EventTimeBins=np.histogram(EventTime, bins=NBins,range=(0,24),density=False) #Storing timestamps in histogram format\n",
    "    #Make a histogram of the V_RMS value fully added in its respective bin by adding V_RMS as a weigth to the additions to the histogram\n",
    "    \n",
    "    EventRMSCountsList=np.array([np.histogram(EventTime, bins=NBins,range=(0,24),density=False,weights=EventRMS[ChIdx]) for ChIdx in np.arange(4)],dtype=object)\n",
    "    #Indexable EventRMSCountsList[ChNr][0 for Counts, 1 for Bins][BinIdx]\n",
    "    \n",
    "    #RMSBins=np.digitize(EventTime,EventTimeBins) #Array of idx of bin in which the timestamp of each event falls\n",
    "    \n",
    "    ##Make a histogram of the V_RMS value fully added in its respective bin by adding V_RMS as a weigth to the additions to the histogram\n",
    "    #EventRMSCounts, EventRMSBins=np.histogram(RMSBins, bins=24,range=(0,24),density=False,weights=EventRMS)\n",
    "    \n",
    "    #Compute std per bin\n",
    "    EventTimeDig=np.digitize(EventTime,EventTimeBins)\n",
    "    GroupedVRMS=np.empty((4,NBins),dtype=object)\n",
    "    for ChIdx in range(4):\n",
    "        for i in range(len(EventTimeDig)):\n",
    "            #print(\"ChIdx: \" + str(ChIdx) + \", EventTimeDig[i]-1:\" + str(EventTimeDig[i]-1) + \",i: \" + str(i))\n",
    "            GroupedVRMS[ChIdx][EventTimeDig[i]-1]=np.append(GroupedVRMS[ChIdx][EventTimeDig[i]-1],EventRMS[ChIdx][i])\n",
    "    ##Get rid of \"None\" entries in beginning of array\n",
    "    for ChIdx in range(4):\n",
    "        for i in range(len(GroupedVRMS[ChIdx])):\n",
    "            GroupedVRMS[ChIdx][i]=np.delete(GroupedVRMS[ChIdx][i], 0) \n",
    "    VRMSStd=np.array([[np.std(GroupedVRMS[ChIdx][i]) if len(GroupedVRMS[ChIdx][i])!=0 else 0 for i in range(len(GroupedVRMS[ChIdx]))] for ChIdx in range(4)])\n",
    "    \n",
    "    MidBins= np.array([(EventTimeBins[i] + EventTimeBins[i+1])/2 for i in range(0,len(EventTimeBins)-1)])           \n",
    "    VRMSAvg=np.array([[EventRMSCountsList[ChIdx][0][i]/EventTimeCounts[i]  if EventTimeCounts[i] !=0 else 0 for i in range(len(EventTimeCounts))] for ChIdx in np.arange(4)])\n",
    "    #Indexabl as VRMSAvg[ChNr][BinIdx]\n",
    "    if False:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.figtext(0.2, 0.8, \"Entries:\" + str(np.sum(EventTimeCounts)), fontsize=18,bbox=dict(edgecolor='black', facecolor='none', alpha=0.2, pad=10.0))\n",
    "        #plt.plot(SamplingTimes*(10**9),TimeTrace,'-')#, label=\"Channel \" + str(ChNr))\n",
    "        #plt.plot(Energies,TritonEnergyLoss,'-',color='r', label=\"Triton\")\n",
    "        #plt.hist(RMSBins, bins=24,range=(0,24),density=False, weights=[EventRMS[i]/EventRMSCounts[i] for i in range(len(EventRMS))])\n",
    "        plt.plot(MidBins,VRMSAvg[0],'.')\n",
    "        plt.grid(color='grey', linestyle='-', linewidth=1,alpha=0.5)\n",
    "        plt.title(\"V_RMS of Station \" + str(StNr) + \", channel \" + str(ChNrs[0]) + \" for \" + str(NRuns) + \" runs between run \" + str(Runs[0]) + \" and run \" + str(Runs[-1]) + \" throughout the day for \" + str(NBins) + \" bins\")\n",
    "        #plt.ylim(-50,50)\n",
    "        #plt.xlim(0,np.max(SamplingTimes*(10**9)))\n",
    "        plt.xlabel(\"Time (hrs)\",fontsize=20)#20)\n",
    "        plt.ylabel(\"V_RMS (V)\",fontsize=20)#20)\n",
    "        plt.xticks(np.arange(0, 24, 1.0),fontsize=25)#15)\n",
    "        plt.yticks(fontsize=25)#15)\n",
    "        #plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "    fig.suptitle(\"Transit curve for StNr \" + str(StNr) + \", for \" + str(np.sum(EventTimeCounts)) + \" entries\", fontsize=25)\n",
    "    #fig.text(0.30, 0.87, r\"Null hypothesis $H_0$: dice are functioning properly and follow a uniform distribution\", fontsize=10)\n",
    "    #plt.subplots_adjust(top=0.82)\n",
    "    #fig.title(r\"Null hypothesis $H_0$: dice are functioning properly and follow a uniform distribution\")\n",
    "    \n",
    "    for i in np.arange(4):\n",
    "        yidx=i%2\n",
    "        if i <2:\n",
    "            xidx=0\n",
    "        else:\n",
    "            xidx=1\n",
    "        \n",
    "        #for j in range(len(GroupedVRMS[i])):\n",
    "            #axs[xidx, yidx].plot(MidBins[j]*np.ones(len(GroupedVRMS[i][j])),1000*GroupedVRMS[i][j])\n",
    "        axs[xidx, yidx].errorbar(MidBins,1000*VRMSAvg[i],yerr=1000*VRMSStd[i],fmt=\".\")\n",
    "        axs[xidx, yidx].plot(MidBins,1000*VRMSAvg[i],'r.')\n",
    "        axs[xidx, yidx].grid(color='grey', linestyle='-', linewidth=1,alpha=0.5)\n",
    "        #axs[0, 0].legend()\n",
    "        axs[xidx, yidx].set_title(\"Channel \" + str(ChNrs[i]), fontsize=20)\n",
    "        if xidx==1:\n",
    "            axs[xidx, yidx].set_xlabel(TimeFormat + \" Time (hrs)\",fontsize=19)\n",
    "        if yidx==0:\n",
    "            axs[xidx, yidx].set_ylabel(r\"$V_{RMS}$ in mV\",fontsize=19)\n",
    "        axs[xidx, yidx].set_xticks(np.arange(0, 24, 1.0))\n",
    "        axs[xidx, yidx].xaxis.set_tick_params(labelsize=18)\n",
    "        axs[xidx, yidx].yaxis.set_tick_params(labelsize=18)\n",
    "        #axs[xidx, yidx].set_yticks(fontsize=25)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    #fig.subplots_adjust(hspace=0.4)\n",
    "    #plt.figtext(0.25, 0.01, \"The analysis indicates a \" + str(np.round(2*100*PVal,4)) + r\"% chance that $H_0$ is true\", fontsize=18)\n",
    "    #plt.text(200,-200,\"The analysis indicates a \" + str(2*100*PVal) + \"% chance that H_0 is true\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fad3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunStartTime(StNr, Run):\n",
    "    \"\"\"Returns the start time of a run in Unix time\"\"\"\n",
    "    CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "    TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np') \n",
    "    #print(datetime.utcfromtimestamp(TriggerTimes[0]))\n",
    "    return TriggerTimes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3700295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunEndTime(StNr, Run):\n",
    "    \"\"\"Returns the end time of a run in Unix time\"\"\"\n",
    "    CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "    TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np') \n",
    "    #print(datetime.utcfromtimestamp(TriggerTimes[0]))\n",
    "    return TriggerTimes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcef51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunsTimeRanges(StNr, Runs):\n",
    "    \"\"\"Returns the time ranges of a list of runs in Unix time\"\"\"\n",
    "    TimeRanges=np.empty((0,2),float)\n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        if os.path.isfile(path+\"/combined.root\"):\n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')\n",
    "            TimeRanges=np.concatenate((TimeRanges,np.array([[TriggerTimes[0],TriggerTimes[-1]]])),axis=0)\n",
    "        \n",
    "    #print(datetime.utcfromtimestamp(TriggerTimes[0]))\n",
    "    return TimeRanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d7c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimedRunList(OGStNr,StNr,RunsRange=[0,100]):\n",
    "    \"\"\"Highly specific function that returns runs of a station StNr that occured during runs RunsRange of another station OGStNr\"\"\"\n",
    "    RunTimes=[RunStartTime(OGStNr, RunsRange[0]),RunStartTime(OGStNr, RunsRange[1])]\n",
    "    RunList=np.array([])\n",
    "    for Run in np.arange(0,1000,dtype=int):\n",
    "        path=Path(StNr,Run)\n",
    "        if os.path.isfile(path+\"/combined.root\") and os.path.isfile(path+\"/daqstatus.root\"):\n",
    "            if RunTimes[0] < RunStartTime(StNr, Run) < RunTimes[1]:\n",
    "                RunList=np.append(RunList,Run)\n",
    "    return RunList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afab3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunsInTimeframe(StNr,t0,t1,Runs=np.arange(1000)):\n",
    "    \"\"\"Returns a list of all runs of this station which are within the given LST range [t0,t1] and in the run range Runs\"\"\"\n",
    "    RunList=np.array([],dtype=int) #Array to store run values\n",
    "    EventList=[]\n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        #if os.path.isdir(path+\"/combined.root\"):\n",
    "        if os.path.isfile(path+\"/combined.root\"):\n",
    "\n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np') \n",
    "            for EvNr in EventNrs:\n",
    "                EvIndex=np.where(EventNrs==EvNr)[0][0]\n",
    "                if t0<=LST(TriggerTimes,EvIndex)<=t1:\n",
    "                    if not Run in RunList:\n",
    "                        RunList=np.append(RunList,int(Run))\n",
    "                        EventList.append([EvNr])\n",
    "                    else:\n",
    "                        EventList[-1].append(EvNr)  \n",
    "\n",
    "    return RunList, EventList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd9e9e",
   "metadata": {},
   "source": [
    "# TransCurveEnvInsp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06182f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GrafanaData(Nr,FileName):\n",
    "    '''Returns Temperature data of the place with number Nr in the cvs file.'''\n",
    "    with open(FileName) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        Value=np.array([])\n",
    "        Time=np.array([])\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                Name=row[Nr+1]\n",
    "                line_count += 1\n",
    "                #print(\"length of row is \" + str(len(row)))\n",
    "            elif len(row)==0:\n",
    "                break\n",
    "            else:\n",
    "                #print(row)\n",
    "                if row[Nr+1]!=\"\":\n",
    "                    #time=row[0]\n",
    "                    time=dt.datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S')\n",
    "                    DataCount=0\n",
    "                    data=float(row[Nr+1])\n",
    "                    Time=np.append(Time,time)\n",
    "                    Value=np.append(Value,data)\n",
    "                    #for data in row[1:]:\n",
    "                    #    if data!='':\n",
    "                    #        1+1\n",
    "                    #        Time=np.append(Time,time)\n",
    "                    #        Temp=np.append(Temp,data)\n",
    "                    \n",
    "                #print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "                #print(row)\n",
    "                line_count += 1\n",
    "            if line_count%50000==0:\n",
    "                print(\"progress of \" + Name + \" \" + str(Nr) + \"/\" + str(len(row)-1) +\" : \" + str(np.round(100*line_count/477430,2)) + '%', end=\"\\r\")\n",
    "        #print(f'Processed {line_count} lines.')\n",
    "        #print(Data)\n",
    "        return Name, Time, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a389ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyGrafanaAvg(LocNr,FileName,TimeRanges,NBins=24,TimeFormat=\"UTC\"):\n",
    "    \"Plots the average of a physical quantity at location number LocNr provided as a csv file FileName from Grafana as a function of LST during a set time ranges TimeRanges (with shape (x,2) in Unix time)\"\n",
    "    Name, AllTime, AllVal = GrafanaData(LocNr,FileName)\n",
    "    \n",
    "    Val=np.array([]) #Array to store value of each sample in the timeranges\n",
    "    Time=np.array([])#Array to store timestamp of each sample in the timeranges\n",
    "    \n",
    "    for i in np.arange(len(AllTime)):\n",
    "        for TimeRange in TimeRanges:\n",
    "            if datetime.utcfromtimestamp(TimeRange[0])<AllTime[i]<datetime.utcfromtimestamp(TimeRange[1]) and (not AllTime[i] in Time):\n",
    "                Val=np.append(Val,AllVal[i])\n",
    "                T=AllTime[i].hour+AllTime[i].minute/60 + AllTime[i].second/3600\n",
    "                if TimeFormat==\"UTC\":\n",
    "                    Time=np.append(Time, T)        \n",
    "                elif TimeFormat==\"LT\": #Greenland Timezone is UTC-3\n",
    "                    Time=np.append(Time, (T-3)%24)\n",
    "                else:\n",
    "                    print(\"Enter a valid TimeFormat\")\n",
    "    TimeCounts, TimeBins=np.histogram(Time, bins=NBins,range=(0,24),density=False) #Storing timestamps in histogram format\n",
    "    #Make a histogram of the V_RMS value fully added in its respective bin by adding V_RMS as a weigth to the additions to the histogram\n",
    "    ValCounts, ValBins=np.histogram(Time, bins=NBins,range=(0,24),density=False,weights=Val)    \n",
    "\n",
    "   \n",
    "    MidBins= np.array([(TimeBins[i] + TimeBins[i+1])/2 for i in range(0,len(TimeBins)-1)])           \n",
    "    ValAvg=np.array([ValCounts[i]/TimeCounts[i]  if TimeCounts[i] !=0 else 0 for i in range(len(ValCounts))])\n",
    "    \n",
    "    #Compute std per bin\n",
    "    TimeDig=np.digitize(Time,TimeBins)\n",
    "    GroupedVal=np.empty((NBins,),dtype=object)\n",
    "    for i in range(len(TimeDig)):\n",
    "        GroupedVal[TimeDig[i]-1]=np.append(GroupedVal[TimeDig[i]-1],Val[i])\n",
    "    ##Get rid of \"None\" entries in beginning of array\n",
    "    for i in range(len(GroupedVal)):\n",
    "        GroupedVal[i]=np.delete(GroupedVal[i], 0) \n",
    "    ValStd=np.array([np.std(GroupedVal[i]) for i in range(len(GroupedVal))])\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.figtext(0.2, 0.8, \"Entries:\" + str(np.sum(TimeCounts)), fontsize=18,bbox=dict(edgecolor='black', facecolor='none', alpha=0.2, pad=10.0))\n",
    "    #for i in range(len(GroupedVal)):\n",
    "    #    plt.plot(MidBins[i]*np.ones(len(GroupedVal[i])),GroupedVal[i])\n",
    "    plt.errorbar(MidBins,ValAvg,yerr=ValStd,fmt=\".\")\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=1,alpha=0.5)\n",
    "    plt.title(\"Average value for \" + str(Name) + \" with \" + str(NBins) + \" bins\")\n",
    "    #plt.ylim(-50,50)\n",
    "    #plt.xlim(0,np.max(SamplingTimes*(10**9)))\n",
    "    plt.xlabel(TimeFormat + \" Time (hrs)\",fontsize=20)#20)\n",
    "    plt.ylabel(\"A.U.\",fontsize=20)#20)\n",
    "    plt.xticks(np.arange(0, 24, 1.0),fontsize=25)#15)\n",
    "    plt.yticks(fontsize=25)#15)\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "    return Name, Time, Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b50a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriggerFilter(StNr, ChNr, Runs,has_rf0,has_rf1,has_ext,has_pps,has_soft):\n",
    "    \"\"\"Returns the runs following the trigger demands\"\"\"\n",
    "    RunsEvts=np.empty((1,2),dtype=int)\n",
    "    Requirements=[has_rf0,has_rf1,has_ext,has_pps,has_soft]\n",
    "           \n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        if os.path.isfile(path+\"/combined.root\") and os.path.isfile(path+\"/daqstatus.root\"):\n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            TriggerInfo=TrigInfo(StNr,ChNr,Run)\n",
    "            for EvtIdx in range(len(EventNrs)):\n",
    "                Triggers=[TriggerInfo[\"trigger_info.radiant_info.RF_window[2]\"][EvtIdx][0],TriggerInfo[\"trigger_info.radiant_info.RF_window[2]\"][EvtIdx][1],TriggerInfo[\"trigger_info.ext_trigger\"][EvtIdx],TriggerInfo[\"trigger_info.pps_trigger\"][EvtIdx],TriggerInfo[\"trigger_info.force_trigger\"][EvtIdx]] \n",
    "                if all([Triggers[i]==Requirements[i] or not Requirements[i] in [1,0] for i in range(len(Triggers))]):\n",
    "                    #RunsEvts=np.append(RunsEvts,[Run,EvtIdx])\n",
    "                    RunsEvts=np.concatenate((RunsEvts,np.array([[Run,EventNrs[EvtIdx]]])),axis=0)\n",
    "\n",
    "    return RunsEvts[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dad0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriggerFilterAlt(StNr, ChNr, Runs,has_rf,has_ext,has_pps,has_soft):\n",
    "    \"\"\"Returns the runs following the trigger demands\"\"\"\n",
    "    RunsEvts=np.empty((1,2),dtype=int)\n",
    "    Requirements=[has_rf,has_ext,has_pps,has_soft]\n",
    "           \n",
    "    for Run in Runs:\n",
    "        path=Path(StNr,Run)\n",
    "        if os.path.isfile(path+\"/combined.root\") and os.path.isfile(path+\"/daqstatus.root\"):\n",
    "            CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "            EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "            TriggerInfo=TrigInfo(StNr,ChNr,Run)\n",
    "            for EvtIdx in range(len(EventNrs)):\n",
    "                if TriggerInfo['trigger_info.which_radiant_trigger'][EvtIdx]<-100:\n",
    "                    HasRFTrigger=0\n",
    "                else:\n",
    "                    HasRFTrigger=1\n",
    "                Triggers=[HasRFTrigger,TriggerInfo[\"trigger_info.ext_trigger\"][EvtIdx],TriggerInfo[\"trigger_info.pps_trigger\"][EvtIdx],TriggerInfo[\"trigger_info.force_trigger\"][EvtIdx]] \n",
    "                if all([Triggers[i]==Requirements[i] or not Requirements[i] in [1,0] for i in range(len(Triggers))]):\n",
    "                    #RunsEvts=np.append(RunsEvts,[Run,EvtIdx])\n",
    "                    RunsEvts=np.concatenate((RunsEvts,np.array([[Run,EventNrs[EvtIdx]]])),axis=0)\n",
    "\n",
    "    return RunsEvts[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f508a3e",
   "metadata": {},
   "source": [
    "# Frequency windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e5af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NotchFilters(CritFreqs,Q,Freqs,SamplingRate):\n",
    "    from scipy import signal\n",
    "    NotchFilters=np.empty((1,len(Freqs)),dtype=object)\n",
    "    for freq in CritFreqs:\n",
    "        b,a=signal.iirnotch(freq, Q, fs=SamplingRate)\n",
    "        w, h = signal.freqs(b, a,worN=2*np.pi*Freqs)\n",
    "        freqa, h = signal.freqz(b, a, worN=2*np.pi*Freqs,fs=2*np.pi*SamplingRate)        \n",
    "        NotchFilters=np.concatenate((NotchFilters,np.array([np.abs(h)])),axis=0)\n",
    "    NotchFilters=np.delete(NotchFilters,0,0)\n",
    "    TotalFilter=np.prod(NotchFilters,axis=0)\n",
    "    #plt.figure()\n",
    "    #plt.plot(Freqs,TotalFilter)\n",
    "    #plt.xlim(0,1.5*10**9)\n",
    "    #plt.xlim(3*10**8,5*10**8)\n",
    "    #plt.show()\n",
    "    return TotalFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5d44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LowpassButter(CritFreq,N,Freqs):\n",
    "    from scipy import signal\n",
    "    b,a=signal.butter(N, 2*np.pi*CritFreq, btype='low', analog=True, output='ba', fs=None)\n",
    "    w, h = signal.freqs(b, a,worN=2*np.pi*Freqs)\n",
    "    #plt.figure()\n",
    "    #plt.plot(Freqs,TotalFilter)\n",
    "    #plt.xlim(0,1.5*10**9)\n",
    "    #plt.xlim(3*10**8,5*10**8)\n",
    "    #plt.show()\n",
    "    return np.abs(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a6b028",
   "metadata": {},
   "source": [
    "# GalaxyNoiseSpectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7c5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GalacticNoiseSpectrum(StNr,ChNr,Run,EvtNr,Plot=False):\n",
    "    import NuRadioReco.modules.channelGalacticNoiseSpectrum\n",
    "    from NuRadioReco.detector import detector\n",
    "    from NuRadioReco.utilities import units\n",
    "    from NuRadioReco.framework import event,station, channel\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,Run)\n",
    "    RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "    EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "    TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')  \n",
    "    \n",
    "    EvIndex=np.where(EventNrs==EvtNr)[0][0]\n",
    "    Date=datetime.utcfromtimestamp(TriggerTimes[EvIndex]) - timedelta(hours=3, minutes=0)\n",
    "    \n",
    "    GNDetector = detector.Detector(json_filename = \"/mnt/c/Users/Jethro/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Python 3.8/NuRadioMC/NuRadioReco/detector/RNO_G/RNO_season_2021.json\")\n",
    "    GNDetector.update(Date) #date in example\n",
    "    GNEvent=event.Event(Run,EvtNr)\n",
    "    GNStation=station.Station(StNr)\n",
    "    GNStation.set_station_time(Date)\n",
    "    GNChannel=channel.Channel(ChNr)\n",
    "    GNChannel.set_trace(trace=np.zeros(2048), sampling_rate=3.2 * units.GHz)\n",
    "    GNStation.add_channel(GNChannel) \n",
    "    \n",
    "    \n",
    "    channelGalacticNoiseAdder = NuRadioReco.modules.channelGalacticNoiseSpectrum.channelGalacticNoiseAdder()\n",
    "    channelGalacticNoiseAdder.begin(debug=False,n_side=4,interpolation_frequencies=np.arange(10 * units.MHz, 1100 * units.MHz,100*units.MHz))\n",
    "    GalacticNoiseTrace=channelGalacticNoiseAdder.run(GNEvent,GNStation,GNDetector,passband=[10 * units.MHz, 1000 * units.MHz])\n",
    "    \n",
    "    sampling_rate=3.2 * (10**9) #Sampling rate in Hertz according to the python file of NuRadioReco.modules.io.rno_g\n",
    "    TimeStep=1/sampling_rate #Time between two samples\n",
    "    SamplingTimes=np.arange(0,len(RadiantData[0][0])*TimeStep,TimeStep)\n",
    "    GalacticNoiseSpec=scfft.fft(GalacticNoiseTrace)\n",
    "    GalacticNoiseSpec=np.fft.fftshift(GalacticNoiseSpec)\n",
    "    freq=scfft.fftfreq(len(SamplingTimes),(SamplingTimes[-1]-SamplingTimes[0])/len(SamplingTimes))\n",
    "    freq=np.fft.fftshift(freq)\n",
    "    \n",
    "    if Plot:\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.title(\"Galactic noise spectrum of Station \" + str(StNr) + \", channel \" + str(ChNr) + \", run \" + str(Run) + \", event \" + str(EvtNr) + \" at \" + str(Date.replace(microsecond=0) ) + \" LT\",fontsize=20)\n",
    "        #plt.plot(GNChannel.get_frequencies()/units.MHz,np.abs(GalacticNoiseSpec))\n",
    "        plt.plot(freq,np.abs(GalacticNoiseSpec))\n",
    "        plt.xlim(0,1.5*10**9)\n",
    "        plt.show()\n",
    "    return freq, np.abs(GalacticNoiseSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c52028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GalacticNoiseVRMSCurve(StNr,ChNr,RunsEvts,LowPass=False):\n",
    "    EventRMS=np.array([])\n",
    "    EventTime=np.array([])\n",
    "    for (RunNr,EvNr) in RunEvts:\n",
    "        CombinedFile, DAQStatFile, HeadersFile, PedestalFile=FilesStRun(StNr,RunNr)\n",
    "        RadiantData=CombinedFile['combined']['waveforms']['radiant_data[24][2048]'].array(library='np')\n",
    "        EventNrs=CombinedFile['combined']['waveforms']['event_number'].array(library=\"np\")\n",
    "        TriggerTimes=CombinedFile['combined']['header'][\"trigger_time\"].array(library='np')  \n",
    "        \n",
    "        EvIndex=np.where(EventNrs==EvNr)[0][0]\n",
    "        EventTime=np.append(EventTime,LST(TriggerTimes,EvIndex))\n",
    "        \n",
    "        GNFreq,GNSpec=GalacticNoiseSpectrum(22,13,RunNr,EvNr,Plot=False)\n",
    "        \n",
    "        if LowPass:\n",
    "            CritFreq=110*10**6\n",
    "            GNSpec=np.array([GNSpec[i]*LowpassButter(CritFreq,20,GNFreq)[i] for i in range(len(GNFreq))])\n",
    "            \n",
    "        EventRMS=np.append(EventRMS,np.sqrt(np.sum(np.abs(GNSpec)**2)))\n",
    "        \n",
    "        #plt.figure(figsize=(20,5))\n",
    "        #plt.title(\"Galactic noise spectrum of Station \" + str(StNr) + \", channel \" + str(ChNr) + \", run \" + str(RunNr) + \", event \" + str(EvNr),fontsize=20)\n",
    "        #plt.plot(GNFreq,np.abs(GNSpec))\n",
    "        #plt.xlim(0,1.5*10**9)\n",
    "        #plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    #plt.figtext(0.2, 0.8, \"Entries:\" + str(np.sum(EventTimeCounts)), fontsize=18,bbox=dict(edgecolor='black', facecolor='none', alpha=0.2, pad=10.0))\n",
    "    #plt.hist(RMSBins, bins=24,range=(0,24),density=False, weights=[EventRMS[i]/EventRMSCounts[i] for i in range(len(EventRMS))])\n",
    "    #plt.errorbar(MidBins,1000*VRMSAvg,yerr=1000*VRMSStd,fmt=\".\",zorder=2)\n",
    "    #for i in range(len(GroupedVRMS)):\n",
    "    #    plt.plot(MidBins[i]*np.ones(len(GroupedVRMS[i])),1000*GroupedVRMS[i],\"r.\", alpha=0.5,zorder=1)\n",
    "    \n",
    "    #plt.plot(MidBins,1000*VRMSAvg,'r.')\n",
    "    plt.plot(EventTime,EventRMS,'.', markersize=20)\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=1,alpha=0.5)\n",
    "    plt.title(\"Galactic noise V_RMS of Station \" + str(StNr) + \", channel \" + str(ChNr) + \" for \" + str(len(RunsEvts)) + \" events\")\n",
    "    #plt.ylim(-50,50)\n",
    "    #plt.xlim(0,np.max(SamplingTimes*(10**9)))\n",
    "    plt.xlabel(\"LST Time (hrs)\",fontsize=20)#20)\n",
    "    plt.ylabel(\"V_RMS (mV)\",fontsize=20)#20)\n",
    "    plt.xticks(np.arange(0, 24, 1.0),fontsize=25)#15)\n",
    "    plt.yticks(fontsize=25)#15)\n",
    "    #plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27cbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
